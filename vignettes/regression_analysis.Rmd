---
title: "Regression Analysis"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Regression Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  out.width = "100%",
  out.height = "100%",
  fig.width = 12,
  fig.height = 9
)
```

```{r development, eval=FALSE, include=FALSE}
# devtools::document()
# devtools::load_all()
# renv::snapshot(prompt = F)

```


```{r setup}
# Clear working environment
rm(list=ls())

library(bnaiaR)
library(dplyr)
library(ggplot2)
library(forcats)
library(mgcv)
library(doParallel)

set.seed(100)

SAVEPLOTS <- F
PLOTPATH <- Sys.getenv("PLOTPATH")
PLOTWIDTH = 16
PLOTHEIGHT = 9
```

# Load and Prepare Data for Regression Modelling

```{r load_data}
data("adbisgc")
str(adbisgc, give.attr=F)
summarytools::dfSummary(adbisgc)
```


```{r}
adbisgc_reg <- adbisgc %>%
  mutate(gender = fct_relevel(gender,c("male","female"))) %>%
  # mutate(age_diag_group = fct_relevel(age_diag_group, c(LETTERS[seq(8,1,-1)]))) %>% # keep them alphabetically.
  mutate(positive_famillial_history = fct_relevel(positive_famillial_history, c("no", "probably", "yes"))) %>%
  mutate(smoking_current_former_no = fct_relevel(smoking_current_former_no, c("no","former","current"))) %>%
  mutate(smoking_current_notcurrent = fct_relevel(smoking_current_notcurrent, c("not_current", "current"))) %>%
  mutate(multipleIAs = fct_relevel(multipleIAs, c("no", "yes"))) %>%
  mutate(hpt_aware = fct_relevel(hpt_aware,c("no","yes"))) %>%
  mutate(IAlocation_group = fct_relevel(IAlocation_group, c("low","medium","high")))%>%
  mutate(IAruptured = fct_relevel(IAruptured,c("no","yes"))) 
  # mutate(IAsize_diag_grouped_merged = fct_relevel(IAsize_diag_grouped_merged, c(LETTERS[seq(3,1,-1)])))
str(adbisgc_reg, give.attr=F)
# summarytools::dfSummary(adbisgc_reg)
```


## Select bnaiaR variables


```{r}
bnaiar_vars <- c("ID_1", 
           "study_source", 
           "gender", 
           "age_diag", "age_diag_group", 
           "positive_famillial_history", 
           "hpt_aware", 
           "smoking_current_notcurrent", 
           "multipleIAs", 
           "IAlocation", "IAlocation_group", 
           "IAsize_diag", "IAsize_diag_log", "IAsize_diag_grouped", "IAsize_diag_grouped_merged",
           "IAruptured")

df_bnaiar <- adbisgc_reg %>%
  select(all_of(bnaiar_vars))
```

```{r}
summarytools::dfSummary(df_bnaiar)
# summarytools::view(dfSummary(df_bnaiar), method = "pander", file = "~/ZHAW/ExplorDataISGC/220623_HUG-ZHAW_Retreat/summary_adbisgc_bnaiaR.html")
str(df_bnaiar, give.attr=F)
```



```{r}
# df_bnaiar %>%
#   # dataxray::report_xray(data_name = "bnaiaR", study = "multicentre")
#   dataxray::make_xray() %>%
#   dataxray::view_xray()
```


```{r}
# plt <- df_bnaiar %>%
#   select(-c(ID_1)) %>%
#   
#   ggpairs(ggplot2::aes(colour=source),
#                upper = list(
#                  continuous = wrap("cor", method="spearman", size=15),
#                  discrete = wrap("facetbar", binwidth=5),
#                  combo = wrap("facethist", binwidth=5)
#                  # combo = "summarise_by"
#                  ),
#                lower = list(
#                  continuous = wrap("smooth", binwidth=5),
#                  discrete = wrap("colbar", size=7),
#                  combo = wrap("box", width=5)
#                ),
#                proportions = "auto") +
#   theme(text = element_text(size = 30), 
#         axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
#         strip.text.x = element_text(angle = 30, vjust = 0.5), 
#         strip.text.y = element_text(angle = 0, vjust = 0.5), 
#         strip.placement = "outside") 
# 
# ggsave(plot = plt,
#        filename = "bnaiar_adbisgc_scatterplot.pdf", 
#          path = "~/ZHAW/ExplorDataISGC/", 
#          width = 100, height = 80, limitsize = F,
#          # width = 150, height = 150, limitsize = F,
#          device = "pdf")
```

## bnaiaR vars with only complete entries

count the number of NAs per source

```{r}
NAs_per_source <- adbisgc_reg %>%
  select(all_of(c(bnaiar_vars, "data_source"))) %>%
  
  group_by(data_source) %>% 
  do(data.frame(total=nrow(.),
                # NAs = sum(is.na(.)),
                complete = nrow(na.omit(.)))) %>%
  mutate(NAs = total - complete,
         comment = NA)
  
NAs_per_source$comment[which(NAs_per_source$data_source == "kuopio")] <- "4% of values are missing hypertension."
NAs_per_source$comment[which(NAs_per_source$data_source == "ucl")] <- "17% of IA size and 2% of IA location values are missing"
NAs_per_source$comment[which(NAs_per_source$data_source == "nantes")] <- "Many missing age (5%), IA location (3%), IA size (3%) and IA ruptured (6%) values."
NAs_per_source$comment[which(NAs_per_source$data_source == "utrecht")] <- "Many missing smoking (11%) and multiplicity (4%) values."
NAs_per_source$comment[which(NAs_per_source$data_source == "utrecht_ruptured")] <- "Many missing IA size (46%) and smoking (37%) values."
NAs_per_source$comment[which(NAs_per_source$data_source == "geneva_aneuquest")] <- "Many pos. fam. history (12%) and hypertension (7%) are missing."
NAs_per_source$comment[which(NAs_per_source$data_source == "geneva_aneux")] <- "Many missing pos. fam. history (7%) values."

NAs_per_source

# df_bnaiar %>%
#   filter(data_source == "geneva_aneux") %>%
#   dfSummary()
```

```{r}
df_bnaiar_compl <- df_bnaiar %>%
  na.omit() 

summarytools::dfSummary(df_bnaiar_compl)
```


# Multiple Logistic Regression Model 



## Log reg for IA Rupture

As in Figure 6 in Morel et al. 2022.

```{r}
data.logreg <- adbisgc_reg %>%
  select(all_of(c(bnaiar_vars, "smoking_current_former_no"))) %>%
  na.omit() %>%
  
  select(c(IAlocation_group, smoking_current_former_no, multipleIAs, gender, hpt_aware, IAruptured)) %>%
  mutate(IAlocation_group = case_when(IAlocation_group =="high" ~ "high_risk_loc",
                                      IAlocation_group =="medium" ~ "medium_risk_loc",
                                      IAlocation_group =="low" ~ "low_risk_loc"),
         multipleIAs = case_when(multipleIAs == "yes" ~ "multipleIAs",
                                 multipleIAs == "no" ~ "singularIA"),
         smoking_current_former_no = case_when(smoking_current_former_no == "no" ~ "non_smoker",
                                               smoking_current_former_no == "current" ~ "current_smoker",
                                               smoking_current_former_no == "former" ~ "former_smoker"),
         hpt_aware = case_when(hpt_aware == "no" ~ "hpt_unaware",
                               hpt_aware == "yes" ~ "hpt_aware"),
         IAruptured = case_when(IAruptured == "no" ~ "unruptured_IA",
                                IAruptured == "yes" ~ "ruptured_IA")) %>%
  
  mutate(IAlocation_group = factor(IAlocation_group, levels = c("low_risk_loc", "medium_risk_loc", "high_risk_loc")),
         multipleIAs = factor(multipleIAs, levels = c("singularIA", "multipleIAs")),
         smoking_current_former_no= factor(smoking_current_former_no, levels = c("non_smoker", "former_smoker", "current_smoker")),
         hpt_aware = factor(hpt_aware, levels = c("hpt_unaware", "hpt_aware")),
         IAruptured = factor(IAruptured, levels = c("unruptured_IA", "ruptured_IA")))

str(data.logreg, give.attr=F)
```


### Data preparation

```{r}
train <- sample.int(n = nrow(data.logreg), size = 0.7*nrow(data.logreg), replace = FALSE)
TrainSet <- data.logreg[train,]
ValidSet <- data.logreg[-train,]
str(TrainSet, give.attr=F)
summary(TrainSet)
str(ValidSet, give.attr=F)
summary(ValidSet)
```



```{r}
glm_model <- glm(IAruptured ~.,family=binomial(link='logit'),data=TrainSet)
summary(glm_model)

plt <- sjPlot::plot_model(glm_model,
           show.values = TRUE, 
           value.offset = .3, 
           sort.est=TRUE,  
           line.size = 1.5, 
           dot.size = 3, #
           # transform="plogis", # plots probabilities
           # value.size	= 4,
           title = "Logistic regression for IA rupture in ADB") +
  ylab("Odds ratios") +
  geom_hline(yintercept = 1) +
  theme_light()

if (SAVEPLOTS){
  plt.mod <- plt +
    sjPlot::font_size(
                      title = 15,
                      axis_title.y = 15,
                      axis_title.x = 15,
                      labels.x = 15,
                      labels.y = 15,
                      base.theme = theme_light())
  ggsave(plot = plt.mod, filename = "logreg_IArupture.png", path = PLOTPATH, 
         # dpi = 600, width = 4096, height = 3072, units = "px")
         dpi = 600, width = 4096, height = 2304, units = "px")
} else {
  plt
}
```


```{r}
glm_model
ANOVA <- anova(glm_model,test="Chisq")
ANOVA


pscl::pR2(glm_model)
pred_glm <- predict(glm_model,newdata=ValidSet,type='response')
table(ValidSet$IAruptured, pred_glm > 0.5)

roc <- pROC::roc(ValidSet$IAruptured, pred_glm)
auc <- roc$auc
aucCI <- round(pROC::ci.auc(ValidSet$IAruptured, pred_glm), 2)
plotROCAUC(roc, aucCI, FILENAME = "logreg_IArupture_roc.png", PLOTPATH = PLOTPATH)

pred_glm.rocr <- ROCR::prediction(pred_glm, ValidSet$IAruptured)
perf.acc <- ROCR::performance(pred_glm.rocr, measure="acc", x.measure = "cutoff")
ROCR::plot(perf.acc, main = "Auccuracy")
# abline(v = 0.5)

perf.precrec <- ROCR::performance(pred_glm.rocr, measure="prec", x.measure="rec")
plot(perf.precrec, 
     main = "Precision/recall")

paste("Accuracy = ", max(perf.acc@y.values[[1]]))
perf.acc@x.values[[1]][which(perf.acc@y.values[[1]] == max(perf.acc@y.values[[1]]))]
# perf.acc@y.values[[1]][max(which(perf.acc@x.values[[1]] >= 0.5))]

## Accuraccy as in Morel et al 2021 for verification:
# why 0.48?
pred_glm <- ifelse(pred_glm > 0.53,"Yes","No")
misClasificError <- mean(pred_glm != ValidSet$Ruptured_IA)
format(misClasificError, digits = 2)
lp_accuracy_glm <- (paste("Accuracy = ",1-misClasificError))
lp_accuracy_glm
```


## Log reg for IA Rupture including all Variables

```{r}
data.logreg.all <- adbisgc_reg %>%
  select(all_of(c(bnaiar_vars))) %>%
  # remove duplicate variable-versions. Keep contiunuous vars and IA locations by risk.
  select(-c(age_diag_group, IAlocation, IAsize_diag, IAsize_diag_grouped, IAsize_diag_grouped_merged, ID_1)) %>%
  # remove NAs
  na.omit()

str(data.logreg.all, give.attr=F)
```

### Data preparation

```{r}
train <- sample.int(n = nrow(data.logreg.all), size = 0.7*nrow(data.logreg.all), replace = FALSE)
TrainSet <- data.logreg.all[train,]
ValidSet <- data.logreg.all[-train,]
```

Cross-validation

```{r message=FALSE, warning=FALSE}
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

# defining training control
# as Leave One Out Cross Validation
train_control <- caret::trainControl(method = "LOOCV",
# train_control <- caret::trainControl(method = "optimism_boot", # much faster but only slightly better performance
                                     summaryFunction = caret::prSummary,
                                     # summaryFunction = caret::twoClassSummary,
                                     classProbs = TRUE,
                                     savePredictions = "all")
 
# training the model by assigning IAruptured column
# as target variable and rest other column
# as independent variable
glm_model.logreg.all <- caret::train(IAruptured ~., data = data.logreg.all,
               method = "glm",
               family=binomial(link='logit'),
               trControl = train_control)
 
stopCluster(cl)

# printing model performance metrics
# along with other details
print(glm_model.logreg.all)
print(summary(glm_model.logreg.all))

loocv.cm.logreg <- caret::confusionMatrix(glm_model.logreg.all$pred$pred, glm_model.logreg.all$pred$obs, positive = "yes", mode = "everything")
df.predmetrics <- data.frame(loocv.logreg = round(c(loocv.cm.logreg$overall, loocv.cm.logreg$byClass), 3))
df.predmetrics
```

70:30 split

```{r}
# TODO: sjPlot doesn't run with caret glm model... see old version of this vignette.

# summary (glm_model.logreg.all)
# 
# plt <- sjPlot::plot_model(glm_model.logreg.all,
#            show.values = TRUE, 
#            value.offset = .3, 
#            sort.est=TRUE,  
#            line.size = 1.5, 
#            dot.size = 3, #,transform="plogis" plots probabilities
#            title = "Logistic regression for IA rupture") +
#   ylab("Odds ratios") +
#   geom_hline(yintercept = 1) +
#   theme_light() 
# 
# if (SAVEPLOTS){
#   plt.mod <- plt +
#     sjPlot::font_size(
#                       title = 15,
#                       axis_title.y = 15,
#                       axis_title.x = 15,
#                       labels.x = 15,
#                       labels.y = 15,
#                       base.theme = theme_light())
#   ggsave(plot = plt.mod, filename = "logreg_IArupture_allvars.png", path = PLOTPATH, 
#          dpi = 600, width = 4096, height = 4096, units = "px")
#          # dpi = 600, width = 4096, height = 2304, units = "px")
# } else {
#   plt
# }
# 
# sjPlot::tab_model(glm_model.logreg.all)
```



```{r}
# glm_model.logreg.all
# ANOVA.logreg.all <- anova(glm_model.logreg.all,test="Chisq")
# ANOVA.logreg.all$`Pr(>Chi)`
# ANOVA.logreg.all
# 
# 
# pscl::pR2(glm_model.logreg.all)
# pred_glm.logreg.all <- predict(glm_model.logreg.all,newdata=ValidSet,type='response')
# table(ValidSet$`Ruptured IA`, pred_glm.logreg.all > 0.5)
# 
# 
# conf.mat <- table(as.numeric(ValidSet$`Ruptured IA`), as.numeric(pred_glm.logreg.all>0.5))
# colnames(conf.mat) <- rownames(conf.mat) <- c("No", "Yes")
# 
# split.cm.logreg.all <- caret::confusionMatrix(conf.mat, mode = "everything", positive = "Yes")
# df.predmetrics <- cbind(df.predmetrics, data.frame(split.logreg = round(c(split.cm.logreg.all$overall, split.cm.logreg.all$byClass), 3)))
# df.predmetrics
# 
# roc.logreg.all <- pROC::roc(ValidSet$`Ruptured IA`, pred_glm.logreg.all)
# aucCI.logreg.all <- round(pROC::ci.auc(ValidSet$`Ruptured IA`, pred_glm.logreg.all), 2)
# plotROCAUC(roc.logreg.all, aucCI.logreg.all, FILENAME = "logreg_IArupture_allvars_roc.png", PLOTPATH = PLOTPATH)
# 
# pred.logreg.all.rocr <- ROCR::prediction(pred_glm.logreg.all, ValidSet$`Ruptured IA`)
# perf.acc.logreg.all <- ROCR::performance(pred.logreg.all.rocr, measure="acc", x.measure = "cutoff")
# ROCR::plot(perf.acc.logreg.all, main = "Auccuracy")
# 
# perf.precrec.logreg.all <- ROCR::performance(pred.logreg.all.rocr, measure="prec", x.measure="rec")
# plot(perf.precrec.logreg.all, 
#      main = "Precision/recall")
# 
# paste("Accuracy = ", max(perf.acc.logreg.all@y.values[[1]]))
# max.acc.cutoff <- perf.acc.logreg.all@x.values[[1]][which(perf.acc.logreg.all@y.values[[1]] == max(perf.acc.logreg.all@y.values[[1]]))]
# paste("Cutoff with max. Accuracy = ", max.acc.cutoff)
# # perf.acc.logreg.all@y.values[[1]][max(which(perf.acc.logreg.all@x.values[[1]] >= 0.5))]
# 
# ## Accuraccy as in Morel et al 2021 for verification:
# pred_glm.logreg.all <- ifelse(pred_glm.logreg.all > max.acc.cutoff,"Yes","No")
# misClasificError.logreg.all <- mean(pred_glm.logreg.all != ValidSet$`Ruptured IA`)
# # format(misClasificError.logreg.all, digits = 2)
# lp_accuracy_glm.logreg.all <- (paste("Accuracy = ",1-misClasificError.logreg.all))
# lp_accuracy_glm.logreg.all
```

## Log reg for IA Rupture including all Variables but age

```{r}
data.logreg.all.noage <- data.logreg.all %>%
  select(-c(age_diag))
```

### Data preparation

```{r}
train <- sample.int(n = nrow(data.logreg.all.noage), size = 0.7*nrow(data.logreg.all.noage), replace = FALSE)
TrainSet <- data.logreg.all.noage[train,]
ValidSet <- data.logreg.all.noage[-train,]
```



```{r}
glm_model.logreg.all.noage <- glm(IAruptured ~ .,family=binomial(link='logit'),data=TrainSet)
summary(data.logreg.all.noage)

plt <- sjPlot::plot_model(glm_model.logreg.all.noage,
           show.values = TRUE, 
           value.offset = .3, 
           sort.est=TRUE,  
           line.size = 1.5, 
           dot.size = 3, #,transform="plogis" plots probabilities
           title = "Logistic regression for IA rupture in ADB (all variables)") +
  ylab("Odds ratios") +
  geom_hline(yintercept = 1) +
  theme_light() 

if (SAVEPLOTS){
  plt.mod <- plt +
    sjPlot::font_size(
                      title = 15,
                      axis_title.y = 15,
                      axis_title.x = 15,
                      labels.x = 15,
                      labels.y = 15,
                      base.theme = theme_light())
  ggsave(plot = plt, filename = "logreg_IArupture_allvars.png", path = PLOTPATH, 
         dpi = 600, width = 4096, height = 4096, units = "px")
         # dpi = 600, width = 4096, height = 2304, units = "px")
} else {
  plt
}
```



# Multivariate Generalized Additive Model for IA Rupture including all variables

Replacing categorical `AgeDiag.group` with continuous `AgeDiag`.

```{r}
gam_dat <- adbisgc_reg %>%
  select(all_of(c(bnaiar_vars))) %>%
  # remove duplicate variable-versions. Keep contiunuous vars and IA locations by risk.
  select(-c(age_diag_group, IAsize_diag, IAsize_diag_grouped, IAsize_diag_grouped_merged, ID_1)) %>%
  # remove NAs
  na.omit()

str(gam_dat, give.attr=F)
```

### Data preparation

```{r}
train <- sample.int(n = nrow(gam_dat), size = 0.7*nrow(gam_dat), replace = FALSE)
TrainSet <- gam_dat[train,]
ValidSet <- gam_dat[-train,]
```

### Generalized additive model

```{r}
gam_model_1 <- gam(IAruptured ~ gender+positive_famillial_history+hpt_aware+smoking_current_notcurrent+multipleIAs+IAlocation_group+s(IAsize_diag_log)+s(age_diag),
                 data=TrainSet, family = "binomial")
gam_model_2 <- gam(IAruptured ~ gender+s(age_diag)+positive_famillial_history+hpt_aware+smoking_current_notcurrent+multipleIAs+IAlocation+s(IAsize_diag_log), data=TrainSet, family = "binomial")
gam_model_3 <- gam(IAruptured ~ gender+s(age_diag^2)+positive_famillial_history+hpt_aware+smoking_current_notcurrent+multipleIAs+IAlocation_group+s(IAsize_diag_log^2)+study_source, data=TrainSet, family = "binomial")
gam_model_4 <- gam(IAruptured ~ gender+s(age_diag^2)+positive_famillial_history+hpt_aware+smoking_current_notcurrent+multipleIAs+IAlocation+s(IAsize_diag_log^2)+study_source, data=TrainSet, family = "binomial")
gam_model_5 <- gam(IAruptured ~ gender+s(age_diag)+positive_famillial_history+hpt_aware+smoking_current_notcurrent+multipleIAs+IAlocation_group+s(IAsize_diag_log, by = study_source)+study_source, data=TrainSet, family = "binomial")
gam_model_6 <- gam(IAruptured ~ gender*study_source+s(age_diag, by = study_source)+positive_famillial_history*study_source+hpt_aware*study_source+smoking_current_notcurrent*study_source+multipleIAs*study_source+IAlocation*study_source+s(IAsize_diag_log, by = study_source), data=TrainSet, family = "binomial")
gam_model_7 <- gam(IAruptured ~ gender*study_source+s(age_diag)+positive_famillial_history*study_source+hpt_aware*study_source+smoking_current_notcurrent*study_source+multipleIAs*study_source+IAlocation*study_source+s(IAsize_diag_log), data=TrainSet, family = "binomial")

gam_model_8 <- gam(IAruptured ~ gender:study_source+s(age_diag)+positive_famillial_history:study_source+hpt_aware:study_source+smoking_current_notcurrent:study_source+multipleIAs:study_source+IAlocation:study_source+s(IAsize_diag_log), data=TrainSet, family = "binomial")
gam_model_9 <- gam(IAruptured ~ gender:study_source+s(age_diag^2)+positive_famillial_history:study_source+hpt_aware:study_source+smoking_current_notcurrent:study_source+multipleIAs:study_source+IAlocation:study_source+s(IAsize_diag_log^2), data=TrainSet, family = "binomial")
gam_model_10 <- gam(IAruptured ~ gender:study_source+s(age_diag^2)+positive_famillial_history:study_source+hpt_aware:study_source+smoking_current_notcurrent:study_source+multipleIAs:study_source+ IAlocation_group:study_source+s(IAsize_diag_log^2), data=TrainSet, family = "binomial")
gam_model_11 <- gam(IAruptured ~ gender:study_source+s(age_diag^2)+positive_famillial_history:study_source+hpt_aware:study_source+smoking_current_notcurrent:study_source+multipleIAs:study_source+ IAlocation_group:study_source+s(IAsize_diag_log^2) +s(study_source, bs='re'), data=TrainSet, family = "binomial")
```

```{r}
gam_mod_aic <- AIC(gam_model_1, gam_model_2, gam_model_3, gam_model_4, gam_model_5, gam_model_6, gam_model_7, gam_model_8, gam_model_9, gam_model_10, gam_model_11)
gam_mod_aic[order(gam_mod_aic$AIC),]

gam_mod_bic <- BIC(gam_model_1, gam_model_2, gam_model_3, gam_model_4, gam_model_5, gam_model_6, gam_model_7, gam_model_8, gam_model_9, gam_model_10, gam_model_11)
gam_mod_bic[order(gam_mod_bic$BIC),]
```


```{r}
hist(1/(1+exp(residuals.gam(gam_model_3))))
title("Histogram of residuals expit")
abline(v=0.5)


plot(1/(1+exp(predict.gam(gam_model_3))), 1/(1+exp(residuals.gam(gam_model_3))))
abline(v=0.5, h=0.5)
title(main="Expit(residuals) vs. Expit(predicted)")

qqplot(1/(1+exp(predict.gam(gam_model_3))), 1/(1+exp(residuals.gam(gam_model_3))))
abline(v=0.5, h=0.5)
title(main="QQplot of expit(residuals) vs. expit(predicted)")
```

```{r}
hist(1/(1+exp(residuals.gam(gam_model_4))))
title("Histogram of residuals expit")
abline(v=0.5)


plot(1/(1+exp(predict.gam(gam_model_4))), 1/(1+exp(residuals.gam(gam_model_4))))
abline(v=0.5, h=0.5)
title(main="Expit(residuals) vs. Expit(predicted)")

qqplot(1/(1+exp(predict.gam(gam_model_4))), 1/(1+exp(residuals.gam(gam_model_4))))
abline(v=0.5, h=0.5)
title(main="QQplot of expit(residuals) vs. expit(predicted)")
```

```{r}
arm::binnedplot(fitted(gam_model_3), 
           residuals(gam_model_3, type = "response"), 
           nclass = NULL, 
           xlab = "Expected Values", 
           ylab = "Average residual", 
           main = "Binned residual plot", 
           cex.pts = 0.8, 
           col.pts = 1, 
           col.int = "gray")

arm::binnedplot(gam_model_3$model$age, 
           residuals(gam_model_3, type = "response"), 
           nclass = NULL, 
           xlab = "age", 
           ylab = "Average residual", 
           main = "Binned residual plot", 
           cex.pts = 0.8, 
           col.pts = 1, 
           col.int = "gray")

arm::binnedplot(gam_model_3$model$IAsize_diag_log, 
           residuals(gam_model_3, type = "response"), 
           nclass = NULL, 
           xlab = "IAsize_diag_log", 
           ylab = "Average residual", 
           main = "Binned residual plot", 
           cex.pts = 0.8, 
           col.pts = 1, 
           col.int = "gray")

# arm::binnedplot(as.numeric(gam_model_3$model$IAlocation_group),
#            residuals(gam_model_3, type = "response"),
#            nclass = NULL,
#            xlab = "IAlocation_grouped",
#            ylab = "Average residual",
#            main = "Binned residual plot",
#            cex.pts = 0.8,
#            col.pts = 1,
#            col.int = "gray")
# 
# arm::binnedplot(as.numeric(gam_model_3$model$study_source),
#            residuals(gam_model_3, type = "response"),
#            nclass = NULL,
#            xlab = "source",
#            ylab = "Average residual",
#            main = "Binned residual plot",
#            cex.pts = 0.8,
#            col.pts = 1,
#            col.int = "gray")

gam_pred <- predict.gam(gam_model_3, newdata = ValidSet, type = "response")
conf.mat <- table(ValidSet$IAruptured, as.numeric(gam_pred>0.5))
colnames(conf.mat) <- rownames(conf.mat) <- c("No", "Yes")
split.cm.gam <- caret::confusionMatrix(conf.mat, mode = "everything", positive = "Yes")
split.cm.gam
# df.predmetrics <- cbind(df.predmetrics, data.frame(split.gam = round(c(split.cm.gam$overall, split.cm.gam$byClass), 3)))
# df.predmetrics
roc.gam_model <- pROC::roc(ValidSet$IAruptured, gam_pred)
aucCI.gam_model <- round(pROC::ci.auc(ValidSet$IAruptured, gam_pred), 2)
# plotROCAUC(roc.gam_model, aucCI.gam_model, FILENAME = "gam_IArupture_allvars_roc.png", PLOTPATH = PLOTPATH) # TODO: CHeck this function!
plot(roc.gam_model, main = "ROC Curve")
text(0.5, 0.01, paste("AUC=", aucCI.gam_model[2], "(95% CI =", aucCI.gam_model[1], "-", aucCI.gam_model[3], ")"))

gam.check(gam_model_3)
summary.gam(gam_model_3)
plot.gam(gam_model_3, residuals=T, se=TRUE, 
         shade=T, shade.col='gray90', 
         all.terms = T, pages = 1)
abline(h=0)
anova.gam(gam_model_3)
print(gam_model_3)
```

- why is UCL (the only) significantly different source?
- two outliers in the residual plots
- overall nice model...

NIR: "This is the accuracy achievable by always predicting the majority class label." ->by just predicting the majority class we will have an accuracy o 51%
P-Value [Acc > NIR]: "ts enough for the model to offer significantly better performance over the no-information rate as indicated by the p-value."
Kappa: see https://stats.stackexchange.com/a/82187/152981

```{r}
arm::binnedplot(fitted(gam_model_4), 
           residuals(gam_model_4, type = "response"), 
           nclass = NULL, 
           xlab = "Expected Values", 
           ylab = "Average residual", 
           main = "Binned residual plot", 
           cex.pts = 0.8, 
           col.pts = 1, 
           col.int = "gray")

arm::binnedplot(gam_model_4$model$age, 
           residuals(gam_model_4, type = "response"), 
           nclass = NULL, 
           xlab = "age", 
           ylab = "Average residual", 
           main = "Binned residual plot", 
           cex.pts = 0.8, 
           col.pts = 1, 
           col.int = "gray")

arm::binnedplot(gam_model_4$model$IAsize_diag_log, 
           residuals(gam_model_4, type = "response"), 
           nclass = NULL, 
           xlab = "IAsize_diag_log", 
           ylab = "Average residual", 
           main = "Binned residual plot", 
           cex.pts = 0.8, 
           col.pts = 1, 
           col.int = "gray")

gam_pred <- predict.gam(gam_model_4, newdata = ValidSet, type = "response")
conf.mat <- table(ValidSet$IAruptured, as.numeric(gam_pred>0.5))
colnames(conf.mat) <- rownames(conf.mat) <- c("No", "Yes")
split.cm.gam <- caret::confusionMatrix(conf.mat, mode = "everything", positive = "Yes")
split.cm.gam
# df.predmetrics <- cbind(df.predmetrics, data.frame(split.gam = round(c(split.cm.gam$overall, split.cm.gam$byClass), 3)))
# df.predmetrics
roc.gam_model <- pROC::roc(ValidSet$IAruptured, gam_pred)
aucCI.gam_model <- round(pROC::ci.auc(ValidSet$IAruptured, gam_pred), 2)
# plotROCAUC(roc.gam_model, aucCI.gam_model, FILENAME = "gam_IArupture_allvars_roc.png", PLOTPATH = PLOTPATH) # TODO: CHeck this function!
plot(roc.gam_model, main = "ROC Curve")
text(0.5, 0.01, paste("AUC=", aucCI.gam_model[2], "(95% CI =", aucCI.gam_model[1], "-", aucCI.gam_model[3], ")"))

gam.check(gam_model_4)
summary.gam(gam_model_4)
plot.gam(gam_model_4, residuals=T, se=TRUE, 
         shade=T, shade.col='gray90', 
         all.terms = T, pages = 1)
abline(h=0)
anova.gam(gam_model_4)
print(gam_model_4)
```

- two clear and 3 less clear outliers in significant plot
- intercept not significant!
- more degrees of freedom (as expected due to many levels of IAlocation)!
- rest looks similar...

## Generalized Additive Mixed Effects Model


```{r}
gam_model_8 <- gam(IAruptured ~ gender:study_source+s(age_diag)+positive_famillial_history:study_source+hpt_aware:study_source+smoking_current_notcurrent:study_source+multipleIAs:study_source+IAlocation:study_source+s(IAsize_diag_log), data=TrainSet, family = "binomial")
gam_model_9 <- gam(IAruptured ~ gender:study_source+s(age_diag^2)+positive_famillial_history:study_source+hpt_aware:study_source+smoking_current_notcurrent:study_source+multipleIAs:study_source+IAlocation:study_source+s(IAsize_diag_log^2), data=TrainSet, family = "binomial")
gam_model_10 <- gam(IAruptured ~ gender:study_source+s(age_diag^2)+positive_famillial_history:study_source+hpt_aware:study_source+smoking_current_notcurrent:study_source+multipleIAs:study_source+ IAlocation_group:study_source+s(IAsize_diag_log^2), data=TrainSet, family = "binomial")

gam_model_11 <- gam(IAruptured ~ gender:study_source+s(age_diag^2)+positive_famillial_history:study_source+hpt_aware:study_source+smoking_current_notcurrent:study_source+multipleIAs:study_source+ IAlocation_group:study_source+s(IAsize_diag_log^2) +s(study_source, bs='re'), data=TrainSet, family = "binomial")
gam_model_12 <- gam(IAruptured ~ gender+s(age_diag^2)+positive_famillial_history+hpt_aware+smoking_current_notcurrent+multipleIAs+ IAlocation_group+s(IAsize_diag_log^2) +s(study_source, bs='re'), data=TrainSet, family = "binomial") # by = 're' fits a simple random effect model. see ?linear.functional.terms
```

```{r}
gam_mod_aic <- AIC(gam_model_1, gam_model_2, gam_model_3, gam_model_4, gam_model_5, gam_model_6, gam_model_7, gam_model_8, gam_model_9, gam_model_10, gam_model_11, gam_model_12)
gam_mod_aic[order(gam_mod_aic$AIC),]

gam_mod_bic <- BIC(gam_model_1, gam_model_2, gam_model_3, gam_model_4, gam_model_5, gam_model_6, gam_model_7, gam_model_8, gam_model_9, gam_model_10, gam_model_11, gam_model_12)
gam_mod_bic[order(gam_mod_bic$BIC),]
```

We can see, that considering source as fixed effect (model 12) slightly improves 
the model compared to modeling source as additional covariate (model 3).

```{r}
hist(1/(1+exp(residuals.gam(gam_model_12))))
title("Histogram of residuals expit")
abline(v=0.5)


plot(1/(1+exp(predict.gam(gam_model_12))), 1/(1+exp(residuals.gam(gam_model_12))))
abline(v=0.5, h=0.5)
title(main="Expit(residuals) vs. Expit(predicted)")

qqplot(1/(1+exp(predict.gam(gam_model_12))), 1/(1+exp(residuals.gam(gam_model_12))))
abline(v=0.5, h=0.5)
title(main="QQplot of expit(residuals) vs. expit(predicted)")
```

```{r}
arm::binnedplot(fitted(gam_model_12), 
           residuals(gam_model_12, type = "response"), 
           nclass = NULL, 
           xlab = "Expected Values", 
           ylab = "Average residual", 
           main = "Binned residual plot", 
           cex.pts = 0.8, 
           col.pts = 1, 
           col.int = "gray")

arm::binnedplot(gam_model_12$model$age, 
           residuals(gam_model_12, type = "response"), 
           nclass = NULL, 
           xlab = "age", 
           ylab = "Average residual", 
           main = "Binned residual plot", 
           cex.pts = 0.8, 
           col.pts = 1, 
           col.int = "gray")

arm::binnedplot(gam_model_12$model$IAsize_diag_log, 
           residuals(gam_model_12, type = "response"), 
           nclass = NULL, 
           xlab = "IAsize_diag_log", 
           ylab = "Average residual", 
           main = "Binned residual plot", 
           cex.pts = 0.8, 
           col.pts = 1, 
           col.int = "gray")

# arm::binnedplot(as.numeric(gam_model_3$model$IAlocation_group),
#            residuals(gam_model_3, type = "response"),
#            nclass = NULL,
#            xlab = "IAlocation_grouped",
#            ylab = "Average residual",
#            main = "Binned residual plot",
#            cex.pts = 0.8,
#            col.pts = 1,
#            col.int = "gray")
# 
# arm::binnedplot(as.numeric(gam_model_3$model$study_source),
#            residuals(gam_model_3, type = "response"),
#            nclass = NULL,
#            xlab = "source",
#            ylab = "Average residual",
#            main = "Binned residual plot",
#            cex.pts = 0.8,
#            col.pts = 1,
#            col.int = "gray")

gam_pred <- predict.gam(gam_model_12, newdata = ValidSet, type = "response")
conf.mat <- table(ValidSet$IAruptured, as.numeric(gam_pred>0.5))
colnames(conf.mat) <- rownames(conf.mat) <- c("No", "Yes")
split.cm.gam <- caret::confusionMatrix(conf.mat, mode = "everything", positive = "Yes")
split.cm.gam
# df.predmetrics <- cbind(df.predmetrics, data.frame(split.gam = round(c(split.cm.gam$overall, split.cm.gam$byClass), 3)))
# df.predmetrics
roc.gam_model <- pROC::roc(ValidSet$IAruptured, gam_pred)
aucCI.gam_model <- round(pROC::ci.auc(ValidSet$IAruptured, gam_pred), 2)
# plotROCAUC(roc.gam_model, aucCI.gam_model, FILENAME = "gam_IArupture_allvars_roc.png", PLOTPATH = PLOTPATH) # TODO: CHeck this function!
plot(roc.gam_model, main = "ROC Curve")
text(0.5, 0.01, paste("AUC=", aucCI.gam_model[2], "(95% CI =", aucCI.gam_model[1], "-", aucCI.gam_model[3], ")"))

gam.check(gam_model_12)
summary.gam(gam_model_12)
plot.gam(gam_model_12, residuals=T, se=TRUE, 
         shade=T, shade.col='gray90', 
         all.terms = T, pages = 1)
abline(h=0)
anova.gam(gam_model_12)
print(gam_model_12)
```

# Multivariate Generalized Linear Mixed Effects Model (mixed effects logistic regression)

Random intercept for 'study_source'

From Lecture notes, sec. 5 `D2 Design and analysis of experiments` of the ACLS Masters program:
In random block effect models, the levels of the blocking factor were chosen randomly
from a (typically much bigger) set of possible levels. The main interest is not in the
effect of blocks, only in the variation introduced by the blocking factor.
Because the model includes both fixed and random effects, it is called a mixed effects
model. This special model is sometimes referred to as random intercept model. It also
makes the assumption that there is no interaction between block and treatment effects.
...
We do not care if the block effect is significant, we only want to correctly estimate
the treatment effect while accounting for the plot structure induced by the blocks.


Starting with a simple model
covariates left untransformed and uncorrelated random effects for the study_source means

```{r}
# x <- lme4::glmer(IAruptured ~ gender+age_diag^2+(0+positive_famillial_history|study_source)+hpt_aware+smoking_current_notcurrent+multipleIAs+ IAlocation_group+IAsize_diag_log^2 + (1|study_source), family = "binomial", data=TrainSet) # uncorrelated random intercept and random slope within group

# Starting with a simple model
# covariates left untransformed and uncorrelated random effects for the study_source means
glmer_model <- lme4::glmer(IAruptured ~ gender+age_diag+positive_famillial_history+hpt_aware+smoking_current_notcurrent+multipleIAs+ IAlocation_group+IAsize_diag_log + (1|study_source), family = "binomial", data=TrainSet) # random group intercept

# equatiomatic::extract_eq(glmer_model, wrap=T, use_coefs = F, terms_per_line = 3)

print(glmer_model)
print(summary(glmer_model))
plot(glmer_model)
```

$$
\begin{aligned}
  \operatorname{IAruptured}_{i}  &\sim \operatorname{Binomial}(n = 1, \operatorname{prob}_{\operatorname{IAruptured} = \operatorname{yes}} = \widehat{P}) \\
    \log\left[\frac{\hat{P}}{1 - \hat{P}} \right] &=\alpha_{j[i]} + \beta_{1}(\operatorname{gender}_{\operatorname{female}}) + \beta_{2}(\operatorname{age\_diag})\ + \\
&\quad \beta_{3}(\operatorname{positive\_famillial\_history}_{\operatorname{probably}}) + \beta_{4}(\operatorname{positive\_famillial\_history}_{\operatorname{yes}}) + \beta_{5}(\operatorname{hpt\_aware}_{\operatorname{yes}})\ + \\
&\quad \beta_{6}(\operatorname{smoking\_current\_notcurrent}_{\operatorname{current}}) + \beta_{7}(\operatorname{multipleIAs}_{\operatorname{yes}}) + \beta_{8}(\operatorname{IAlocation\_group}_{\operatorname{medium}})\ + \\
&\quad \beta_{9}(\operatorname{IAlocation\_group}_{\operatorname{high}}) + \beta_{10}(\operatorname{IAsize\_diag\_\log}) \\
    \alpha_{j}  &\sim N \left(\mu_{\alpha_{j}}, \sigma^2_{\alpha_{j}} \right)
    \text{, for study\_source j = 1,} \dots \text{,J}
\end{aligned}
$$


Now we fit the same model as `gam_model_3` (which was the best performing gam)
with age and size squared.

```{r}
glmer_model_contsqr <- lme4::glmer(IAruptured ~ gender+age_diag^2+positive_famillial_history+hpt_aware+smoking_current_notcurrent+multipleIAs+ IAlocation_group+IAsize_diag_log^2 + (1|study_source), family = "binomial", data=TrainSet) # random group intercept

# equatiomatic::extract_eq(glmer_model_contsqr, wrap=T, use_coefs = F, terms_per_line = 3)

print(glmer_model_contsqr)
print(summary(glmer_model_contsqr))
plot(glmer_model_contsqr)
```

$$
\begin{aligned}
  \operatorname{IAruptured}_{i}  &\sim \operatorname{Binomial}(n = 1, \operatorname{prob}_{\operatorname{IAruptured} = \operatorname{yes}} = \widehat{P}) \\
    \log\left[\frac{\hat{P}}{1 - \hat{P}} \right] &=\alpha_{j[i]} + \beta_{1}(\operatorname{gender}_{\operatorname{female}}) + \beta_{2}(\operatorname{age\_diag})\ + \\
&\quad \beta_{3}(\operatorname{positive\_famillial\_history}_{\operatorname{probably}}) + \beta_{4}(\operatorname{positive\_famillial\_history}_{\operatorname{yes}}) + \beta_{5}(\operatorname{hpt\_aware}_{\operatorname{yes}})\ + \\
&\quad \beta_{6}(\operatorname{smoking\_current\_notcurrent}_{\operatorname{current}}) + \beta_{7}(\operatorname{multipleIAs}_{\operatorname{yes}}) + \beta_{8}(\operatorname{IAlocation\_group}_{\operatorname{medium}})\ + \\
&\quad \beta_{9}(\operatorname{IAlocation\_group}_{\operatorname{high}}) + \beta_{10}(\operatorname{IAsize\_diag\_\log}) \\
    \alpha_{j}  &\sim N \left(\mu_{\alpha_{j}}, \sigma^2_{\alpha_{j}} \right)
    \text{, for study\_source j = 1,} \dots \text{,J}
\end{aligned}
$$



Comparing the two:
```{r}
anova(glmer_model, glmer_model_contsqr)
```

Since both have equal values of AIC, BIC, LL I'd go for the less complex, first model.
Compared to the GAMs, they have smaller BIC values.

















----old code-----

<!-- ```{r} -->
<!-- gam.check(gam_model) -->
<!-- summary.gam(gam_model) -->
<!-- par(mfrow = c(1,8)) -->
<!-- plot.gam(gam_model, residuals=T, se=TRUE,  -->
<!--          shade=T, shade.col='gray90',  -->
<!--          all.terms = T, pages = 1) -->
<!-- abline(h=0) -->

<!-- anova.gam(gam_model) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- if (SAVEPLOTS){ -->
<!--   graphics.off() -->

<!--   PLOTNAME <- "gam_model" -->
<!--   pdf(file = paste0(PLOTPATH, "/", PLOTNAME, ".pdf"), width = PLOTWIDTH*0.7, height = PLOTHEIGHT) -->

<!--   op <- par(mfrow=c(3,3)) -->
<!--             # , mai=c(0.01,0.01,0.01,0.01), mar=c(0.1,0.1,0.1,0.1)) -->
<!--   for (i in 1:9) { -->
<!--     plot.gam(gam_model, select = i, residuals=T, se=TRUE, -->
<!--              shade=T, shade.col='gray90', -->
<!--              all.terms = T) -->
<!--     abline(h=0) -->
<!--     } -->
<!--   par(op) -->

<!--   dev.off() -->
<!-- } else { -->
<!--   op <- par(mfrow=c(3,3)) -->
<!--   for (i in 1:9) { -->
<!--     plot.gam(gam_model, select = i, residuals=T, se=TRUE,  -->
<!--              shade=T, shade.col='gray90',  -->
<!--              all.terms = T)   -->
<!--     abline(h=0) -->
<!--     } -->
<!--   par(op) -->
<!-- } -->
<!-- ``` -->

<!-- ```{r} -->
<!-- gam_pred <- predict.gam(gam_model, newdata = ValidSet, type = "response") -->
<!-- conf.mat <- table(ValidSet$IAruptured, as.numeric(gam_pred>0.5)) -->
<!-- colnames(conf.mat) <- rownames(conf.mat) <- c("No", "Yes") -->

<!-- split.cm.gam <- caret::confusionMatrix(conf.mat, mode = "everything", positive = "Yes") -->
<!-- df.predmetrics <- cbind(df.predmetrics, data.frame(split.gam = round(c(split.cm.gam$overall, split.cm.gam$byClass), 3))) -->
<!-- df.predmetrics -->

<!-- roc.gam_model <- pROC::roc(ValidSet$IAruptured, gam_pred) -->
<!-- aucCI.gam_model <- round(pROC::ci.auc(ValidSet$IAruptured, gam_pred), 2) -->
<!-- plotROCAUC(roc.gam_model, aucCI.gam_model, FILENAME = "gam_IArupture_allvars_roc.png", PLOTPATH = PLOTPATH) # TODO: CHeck this function! -->
<!-- ``` -->

<!-- Cross-validation gam -->

<!-- ```{r message=FALSE, warning=FALSE} -->
<!-- # NOTE! -->
<!-- # CV with caret doesn't work for gam with discrete variables. It basically put each covariate in a spline function s() which is not equivalent to the above model! -->
<!-- # https://stats.stackexchange.com/a/405292/152981 -->

<!-- # # defining training control -->
<!-- # # as Leave One Out Cross Validation -->
<!-- # train_control <- caret::trainControl(method = "LOOCV", -->
<!-- #                                      summaryFunction = caret::prSummary,  -->
<!-- #                                      # summaryFunction = twoClassSummary,  -->
<!-- #                                      classProbs = TRUE, -->
<!-- #                                      savePredictions = "all") -->
<!-- #   -->
<!-- # # training the model by assigning sales column -->
<!-- # # as target variable and rest other column -->
<!-- # # as independent variable -->
<!-- # model <- caret::train(Ruptured_IA ~ Gender+Positive.famillial.history+Hypertension+Smoking_Current_Former_No+location.grouped+IAsize_log+Multiple.IAs+AgeDiag, data = gam_dat, -->
<!-- #                method = "gam", -->
<!-- #                family=binomial(link='logit'), -->
<!-- #                trControl = train_control, -->
<!-- #                tuneGrid = data.frame(method = "GCV.Cp", select = FALSE)) -->
<!-- #   -->
<!-- # # printing model performance metrics -->
<!-- # # along with other details -->
<!-- # print(model) -->
<!-- #  -->
<!-- # loocv.cm.gam <- caret::confusionMatrix(model$pred$pred, model$pred$obs, positive = "Yes", mode = "everything") -->
<!-- # df.predmetrics <- cbind(df.predmetrics, data.frame(loocv.gam = round(c(loocv.cm.gam$overall, loocv.cm.gam$byClass), 3))) -->
<!-- # df.predmetrics -->
<!-- ``` -->

<!-- ```{r} -->
<!-- gam_model_summary <- summary(gam_model) -->
<!-- pltdat <- data.frame(varnames = names(gam_model_summary$p.coeff), coefs = as.numeric(gam_model_summary$p.coeff), pvalue=as.numeric(gam_model_summary$p.pv)) %>% -->
<!--   mutate(expcoefs = exp(coefs)) -->

<!-- ggplot(pltdat)+ -->
<!--   aes(x=varnames, y=coefs)+ -->
<!--   geom_point()+ -->
<!--   ylab("Logit") + -->
<!--   geom_hline(yintercept = 0) + -->
<!--   theme_light() + -->
<!--   coord_flip() -->

<!-- ggplot(pltdat)+ -->
<!--   aes(x=varnames, y=expcoefs)+ -->
<!--   geom_point()+ -->
<!--   ylab("Odds ratios") + -->
<!--   geom_hline(yintercept = 1) + -->
<!--   theme_light() + -->
<!--   coord_flip() -->

<!-- if (SAVEPLOTS){ -->
<!--   # plt.mod <- plt + -->
<!--   #   sjPlot::font_size( -->
<!--   #                     title = 15, -->
<!--   #                     axis_title.y = 15, -->
<!--   #                     axis_title.x = 15, -->
<!--   #                     labels.x = 15, -->
<!--   #                     labels.y = 15, -->
<!--   #                     base.theme = theme_light()) -->
<!--   # ggsave(plot = plt, filename = "gam_IArupture_allvars.png", path = PLOTPATH,  -->
<!--   #        dpi = 600, width = 4096, height = 4096, units = "px") -->
<!--   #        # dpi = 600, width = 4096, height = 2304, units = "px") -->
<!-- } else { -->
<!--   plt -->
<!-- } -->
<!-- ``` -->

<!-- store prediction metrics -->

<!-- ```{r} -->
<!-- write.csv(df.predmetrics, file = paste0(PLOTPATH, "/prediction_metrics_regression.csv")) -->
<!-- ``` -->


