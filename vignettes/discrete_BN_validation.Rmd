---
title: "Model Validation of discrete BN"
author: "Matteo Delucchi"
output:
  rmarkdown::html_document:
    toc: yes
    toc_float:
      collapsed: true
      smooth_scroll: false
    toc_depth: 3
  rmarkdown::html_vignette: default
vignette: >
  %\VignetteIndexEntry{Model Validation of discrete BN}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r development, eval=FALSE, include=FALSE}
# devtools::document()
# devtools::load_all()
# renv::snapshot(prompt = F)
```

```{r setup}
# Clear working environment
rm(list=ls())

# Load libraries
library(bnaiaR)
library(tidyr)
library(dplyr)
library(ggplot2)
library(bnlearn)

set.seed(100)

# Save plots as files? 
SAVEPLOTS <- F
PLOTPATH <- paste0(Sys.getenv("PLOTPATH"), "/fourierplots")
PLOTFORMAT <- "pdf" # "pdf", "svg" or "png"
PLOTWIDTH = 16
PLOTHEIGHT = 9
```


# discrete BN

# discrete BN w/o study source

# discrete BN w/o study_source for each source individually

# discrete BN with study_source as parent of everything

# additive discrete BN

# additive discrete BN with study source as mixed effect

## load data

```{r message=FALSE, warning=FALSE}
load(paste0(PLOTPATH, "/discrete_BN_SL_additive_bic_mixedeffects.RData"))
```


```{r}
data <- tobesaved$madbn_data
bl <- tobesaved$madbn_bl
avg <- tobesaved$madbn_avg
bb <- tobesaved$madbn_boot
```

Plot DAG with study source of averaged bootstrap network and  unrestricted bootstrapped structure-
```{r}
strength.plot(avg, # with increased threshold: averaged.network(bb, threshold = 0.7)
              bb,
              main = "discrete additive mixed-effects BN",
              # sub = "SL: tabu\nth.=0.3\nScore=BIC",
              shape = "rectangle")
```

Fit the averaged DAG.
```{r}
madbn_fit <- bn.fit(data = data, x = avg)
```

Remove study source
```{r}
# remove study_source
avg_mod <- bnlearn::remove.node(avg, "study_source")
bb_mod <-  bb %>%
  filter(from != "study_source") %>%
    filter(to != "study_source")
attr(bb_mod, "nodes") <- attr(bb_mod, "nodes")[-10]
data_mod <- data %>%
  select(-c("study_source"))

strength.plot(avg_mod,
              bb_mod,
              main = "discrete additive mixed-effects BN",
              sub = "Fitting w/o study_source",
              shape = "rectangle")

if (SAVEPLOTS){
  PLOTNAME <- "admeBN_fitting_wo_studysource"  
  if(PLOTFORMAT == "svg"){
    dev.print(svg, filename = paste0(PLOTPATH, "/", PLOTNAME, ".", PLOTFORMAT), width = PLOTWIDTH, height = PLOTHEIGHT)
    dev.off()
  } else if(PLOTFORMAT == "png"){
    dev.print(png, filename = paste0(PLOTPATH, "/", PLOTNAME, ".", PLOTFORMAT), width = PLOTWIDTH, height = PLOTHEIGHT)
    dev.off()
  } else if(PLOTFORMAT == "pdf"){
    dev.print(pdf, file = paste0(PLOTPATH, "/", PLOTNAME, ".", PLOTFORMAT), width = PLOTWIDTH, height = PLOTHEIGHT)
    dev.off()
  } 
} 

madbn_fit_mod <- bn.fit(data = data_mod, x = avg_mod)
```

## Cross-validation for rupture prediction under a mixed-effects model

Trying own prediction implementation with study as mixed effect

```{r}
dmeBN_eval <- cv_ROCAUC(data = data, node = "IAruptured", parents = madbn_fit_mod[["IAruptured"]]$parents)
dmeBN_eval
```

## Same DAG but only fixed-effects (bn.fit)
### Data preparation
10% validation data
90% development data split up again in
  20% test
  80% train
  
```{r}
val_idx <- sample.int(n = nrow(data_mod), size = 0.1*nrow(data_mod), replace = FALSE)
val_dat <- data_mod[val_idx, ]
dev_dat <- data_mod[-val_idx, ]

train_idx <- sample.int(n = nrow(dev_dat), size = 0.8*nrow(dev_dat), replace = FALSE)
train_dat <- dev_dat[train_idx, ]
test_dat <- dev_dat[-train_idx, ]
```

### Fit and prediction
```{r}
train_mod <- bn.fit(x=avg_mod, data = train_dat)
pred <- predict(object = train_mod, data = test_dat, node = "IAruptured", prob = TRUE, method = "parents")
y_predProb <- as.data.frame(cbind(as.character(pred), t(attr(pred, "prob")))) %>%
  mutate(across(!(V1), as.numeric)) %>%
  rename(IArupture_pred = V1,
         no_prob = no,
         yes_prob = yes)
```


### ROC curve

Find optimal classification threshold.
on training data
```{r}
y_test <- ifelse(test_dat[["IAruptured"]] == "yes", 1, 0)
thresholds <- seq(0,1,0.01)
rocdf <- data.frame(probthr = thresholds, tp = rep(NA, length(thresholds)), tn = rep(NA, length(thresholds)), fp = rep(NA, length(thresholds)),
                   fn = rep(NA, length(thresholds)))
# t <- 0.5
for (t_idx in seq(1:length(rocdf$probthr))){
  t <- rocdf$probthr[t_idx]
  y_pred <- ifelse(y_predProb["yes_prob"] > t, 1, 0)
  tp <- ifelse((y_pred == y_test) & (y_pred == 1), 1, 0) # correct predicted rupture
  tn <- ifelse((y_pred == y_test) & (y_pred == 0), 1, 0) # correct predicted no rupture
  fp <- ifelse((y_pred != y_test) & (y_pred == 1), 1, 0) # wrong predicted rupture
  fn <- ifelse((y_pred != y_test) & (y_pred == 0), 1, 0) # wrong predicted no rupture
  
  rocdf$tp[t_idx] <- sum(tp, na.rm = TRUE)
  rocdf$tn[t_idx] <- sum(tn, na.rm = TRUE)
  rocdf$fp[t_idx] <- sum(fp, na.rm = TRUE)
  rocdf$fn[t_idx] <- sum(fn, na.rm = TRUE)
}

rocdf <- rocdf %>%
  mutate(tpr = tp/(tp+fn),
         fpr = fp/(fp+tn),
         fnr = fn/(fn+tp),
         fpr = fp/(fp+tn),
         tnr = tn/(tn+fp),
         youdensJ = abs((tp/(tp+fn))+(fp/(fp+tn))-1)) %>%
  mutate(lrpos = tpr/fpr,
         lrneg = fnr/tnr) %>%
  mutate(dor = lrpos/lrneg,
         f1 = (2*tp)/(2*tp+fp+fn),
         ba = (tpr+tnr)/2)

ggplot(rocdf, aes(x=fpr, y=tpr)) +
  geom_point() +
  geom_line() +
  geom_abline(intercept = 0, slope = 1)

rocdf
```

### AUC

```{r}
area <- NA
for (i in seq(2, nrow(rocdf))){
  area[i] <- abs(rocdf$fpr[i]-rocdf$fpr[i-1])*abs(rocdf$tpr[i]*rocdf$tpr[i-1])
}
auc <-sum(area, na.rm = T)
print(paste("AUC: ", round(auc, 2)))
```

### All metrics

False negatives are worse than false positives, therefore the cutoff should be 
choosen with a high sensitivity (TPR).
The optimal cutoff value that balances tpr and fpr has the smallest youdens' J.
```{r}
print(round(t(rocdf[which.min(rocdf$youdensJ),]),2))
```

## Combine the two roc curves

```{r}
rocdf$type = "no study source"

rocdf_me <- dmeBN_eval$rocdf
rocdf_me$type = "mixed effects"

rbind(rocdf, rocdf_me) %>%
  
  ggplot(aes(x=fpr, y=tpr, color = type)) +
  geom_point() +
  geom_line() +
  geom_abline(intercept = 0, slope = 1) +
  labs(title = "ROC")
```

# additive discrete BN with study source as mixed effect. Size -> location restricted

## load data

```{r message=FALSE, warning=FALSE}
load(paste0(PLOTPATH, "/discrete_BN_SL_additive_bic_mixedeffects_restrictedSizeLoc.RData"))
```


```{r}
data <- tobesaved$madbn_data
bl <- tobesaved$madbn_bl
avg <- tobesaved$madbn_avg
bb <- tobesaved$madbn_boot
```

Plot DAG with study source of averaged bootstrap network and  unrestricted bootstrapped structure-
```{r}
strength.plot(avg, # with increased threshold: averaged.network(bb, threshold = 0.7)
              bb,
              main = "discrete additive mixed-effects BN",
              # sub = "SL: tabu\nth.=0.3\nScore=BIC",
              sub = "IA Size -> IA Location restricted",
              shape = "rectangle")
```

Fit the averaged DAG.
```{r}
madbn_fit <- bn.fit(data = data, x = avg)
```

Remove study source
```{r}
# remove study_source
avg_mod <- bnlearn::remove.node(avg, "study_source")
bb_mod <-  bb %>%
  filter(from != "study_source") %>%
    filter(to != "study_source")
attr(bb_mod, "nodes") <- attr(bb_mod, "nodes")[-10]
data_mod <- data %>%
  select(-c("study_source"))

strength.plot(avg_mod,
              bb_mod,
              main = "discrete additive mixed-effects BN\nIA Size -> IA Location restricted",
              sub = "Fitting w/o study_source",
              shape = "rectangle")

if (SAVEPLOTS){
  PLOTNAME <- "admeBN_fitting_wo_studysource"  
  if(PLOTFORMAT == "svg"){
    dev.print(svg, filename = paste0(PLOTPATH, "/", PLOTNAME, ".", PLOTFORMAT), width = PLOTWIDTH, height = PLOTHEIGHT)
    dev.off()
  } else if(PLOTFORMAT == "png"){
    dev.print(png, filename = paste0(PLOTPATH, "/", PLOTNAME, ".", PLOTFORMAT), width = PLOTWIDTH, height = PLOTHEIGHT)
    dev.off()
  } else if(PLOTFORMAT == "pdf"){
    dev.print(pdf, file = paste0(PLOTPATH, "/", PLOTNAME, ".", PLOTFORMAT), width = PLOTWIDTH, height = PLOTHEIGHT)
    dev.off()
  } 
} 

madbn_fit_mod <- bn.fit(data = data_mod, x = avg_mod)
```

## Cross-validation for rupture prediction under a mixed-effects model

```{r}
dmeBNsizelocrestricted_eval <- cv_ROCAUC(data = data, node = "IAruptured", parents = madbn_fit_mod[["IAruptured"]]$parents)
dmeBNsizelocrestricted_eval
```

## Combine all mixed-effect ROC curves

```{r}
rocdf$type = "no study source"

rocdf_me <- dmeBN_eval$rocdf
rocdf_me$type = "mixed effects"

rocdf_meSizeLocRest <- dmeBNsizelocrestricted_eval$rocdf
rocdf_meSizeLocRest$type <- "Size -> Loc Restricted"

rbind(rocdf, rocdf_me, rocdf_meSizeLocRest) %>%
  
  ggplot(aes(x=fpr, y=tpr, color = type)) +
  geom_point() +
  geom_line() +
  geom_abline(intercept = 0, slope = 1) +
  labs(title = "ROC")
```



















# Old stuff down here



# Cross-validation for predictive accuracy with study-source as random-effect

Provided with a `bn`, the procedure calculates the prediction performance on model
inference without SL.


## Classification Error of rupture status.

```{r}
xval.rupture <- bn.cv(data = data_mod, 
              bn = avg_mod,
              method = "hold-out",
              runs = 50,
              fit = "mle",
              loss = "pred",
              loss.args = list(target="IAruptured"))

df.cvmetrics <-
  data.frame(
    loocv.dbn.clerr = c(
      avgClassError = mean(loss(xval.rupture)),
      sdClassError = sd(loss(xval.rupture)),
      cv.metrics(xval.rupture, returnConfMat = T)$carret_confmat$overall,
      cv.metrics(xval.rupture, returnConfMat = T)$carret_confmat$byClass
    ))
df.cvmetrics
df.cvmetrics %>%
  mutate(loocv.dbn.clerr = round(loocv.dbn.clerr, digits = 2)) %>%
  tibble::rownames_to_column() %>%
  gt::gt() 
# %>%
  # gt::gtsave(path = PLOTPATH, filename = "classification_error_ruptureStatus_madbn_tbl.html")
```

higher sensitivity as in single centric study
pos. and neg predictive values higher as in single centre study
higher precision, recall and F1 score, prevalence, detection rate, detection prevalence and balanced accuracy

```{r}
if (SAVEPLOTS) {
  FILE <- paste0(PLOTPATH, "/", "classification_error_ruptureStatus_madbn", ".")
  if (PLOTFORMAT == "svg") {
    svg(paste0(FILE, PLOTFORMAT))
  } else if (PLOTFORMAT == "png") {
    png(paste0(FILE, PLOTFORMAT))
  }
  plot(xval.rupture,
     xlab = c("BIC.signTH"),
     main = "Classification Error of Rupture Status")
  dev.off()
} else {
  plot(xval.rupture,
     xlab = c("BIC.signTH"),
     main = "Classification Error of Rupture Status")
}
```


## Averaged, Overall Classification Error of Rupture Status

Average predictive accuracy over all nodes. 

```{r}
xval.list.bic <- list()
for (node in nodes(avg_mod)) {
  xval <- bn.cv(
    data = data_mod,
    bn = avg_mod,
    method = "hold-out",
    runs = 50,
    fit = "mle",
    loss = "pred",
    loss.args = list(target = node)
  )
  xval.list.bic[[node]] <- list(xval = xval, 
                            cv.metrics = cv.metrics(xval))
}


accs.bic <- unlist(lapply(unlist(xval.list.bic, recursive = F), `[[`, "acc"))
summary(accs.bic, na.rm = T)
```


From `?bnlearn::bn.cv()`:  
"...  
Classification Error (pred): the prediction error for a single node in a discrete network. Frequentist predictions are used, so the values of the target node are predicted using only the information present in its local distribution (from its parents). Lower values are better.  

Posterior Classification Error (pred-lw and pred-lw-cg): similar to the above, but predictions are computed from an arbitrary set of nodes using likelihood weighting to obtain Bayesian posterior estimates. pred-lw applies to discrete Bayesian networks, pred-lw-cg to (discrete nodes in) hybrid networks. Lower values are better.  
..."  

## Posterior Classification Error of rupture status

So, we can use a Bayesian predictions that use a random set of available nodes for the prediction.

```{r}
xval.bic.bayes <- bn.cv(data = data_mod, 
              bn = avg_mod,
              method = "hold-out",
              runs = 50,
              fit = "mle",
              loss = "pred-lw",
              loss.args = list(target="IAruptured"))
cv.metrics(xval.bic.bayes)

df.cvmetrics.postclerr <-
  data.frame(
    loocv.dbn.postclerr = c(
      avgPostClassError = mean(loss(xval.bic.bayes)),
      sdClassError = sd(loss(xval.bic.bayes)),
      cv.metrics(xval.bic.bayes, returnConfMat = T)$carret_confmat$overall,
      cv.metrics(xval.bic.bayes, returnConfMat = T)$carret_confmat$byClass
    )
  )
df.cvmetrics.postclerr
df.cvmetrics.postclerr  %>%
  mutate(loocv.dbn.postclerr = round(loocv.dbn.postclerr, digits = 2)) %>%
  tibble::rownames_to_column() %>%
  gt::gt() 
```

Save classification metrics

```{r}
write.csv(df.cvmetrics, file = paste0(PLOTPATH, "/prediction_metrics_madbn.csv"))
```


```{r}
if (SAVEPLOTS) {
  FILE <- paste0(PLOTPATH, "/", "post_classification_error_ruptureStatus_madbn", ".")
  if (PLOTFORMAT == "svg") {
    svg(paste0(FILE, PLOTFORMAT))
  } else if (PLOTFORMAT == "png") {
    png(paste0(FILE, PLOTFORMAT), res = 300)
  } else if (PLOTFORMAT == "pdf") {
    pdf(paste0(FILE, PLOTFORMAT))
  }
  plot(xval.bic.bayes, 
     xlab = c("BIC"),
     main = "Posterior Classification Error of Rupture Status")
  dev.off()
} else {
  plot(xval.bic.bayes, 
     xlab = c("BIC"),
     main = "Posterior Classification Error of Rupture Status")
}
```
